# **EGT309 AI Solution Development Project**

## Project: Determine Wine Quality
This project is a Kubernetes-based machine learning system to determine wine quality in a fully containerized enviornment with persistent storage, as well as a user-friendly web interface

## System Architecture
- Data Preprocessing: Cleans & Transform raw data
- Model Training: Trains a predictive model using Machine Learning
- Model Inference: use the trained model to make predictions
- User Interface: web application for user to interact

## Deployment Containers & Services

### Data Preprocessing
- Description: Clean and transform raw CSV data
- Deployment YAML: data-preprocessing-deployment.yaml
- Service YAML: data-preprocessing-servicce.yaml

### Model Training
- Description: Train ML model using cleaned data
- Deployment YAML: model-training-deployment.yaml
- Service YAML: N/A

### Model Inference
- Description: Used trained model to predict wine quality
- Deployment YAML: model-inference-deployment.yaml
- Service YAML: model-inference-service.yaml

### User Interface:
- Description: Provides an interactive web app
- Deployment YAML: user-interface-deployment.yaml
- Service YAML: user-interface-service.yaml

## File Structure
ğŸ“¦AISDP-Project

â”£ ğŸ“‚.github

 â”ƒ â”— ğŸ“‚workflows

 â”£ ğŸ“‚backup data

 â”£ ğŸ“‚data-preprocessing

 â”ƒ â”£ ğŸ“‚data

 â”ƒ â”£ ğŸ“‚raw_data

 â”ƒ â”ƒ â”— ğŸ“œwine_quality_assignment.csv

 â”ƒ â”£ ğŸ“‚__pycache__

 â”ƒ â”£ ğŸ“œdata_preprocessing.dockerfile

 â”ƒ â”£ ğŸ“œpreprocess.py

 â”ƒ â”— ğŸ“œrequirements.txt

 â”£ ğŸ“‚k8s

 â”ƒ â”£ ğŸ“œdata-preprocessing-deployment.yaml

 â”ƒ â”£ ğŸ“œdata-preprocessing-service.yaml

 â”ƒ â”£ ğŸ“œmodel-inference-deployment.yaml

 â”ƒ â”£ ğŸ“œmodel-inference-service.yaml

 â”ƒ â”£ ğŸ“œmodel-training-deployment.yaml

 â”ƒ â”£ ğŸ“œpvc.yaml

 â”ƒ â”£ ğŸ“œraw-data-pvc.yaml

 â”ƒ â”£ ğŸ“œuser-interface-deployment.yaml

 â”ƒ â”— ğŸ“œuser-interface-service.yaml

 â”£ ğŸ“‚kubernetes

 â”£ ğŸ“‚mnt

 â”ƒ â”£ ğŸ“‚models

 â”ƒ â”£ ğŸ“‚raw_data

 â”ƒ â”— ğŸ“‚user

 â”£ ğŸ“‚model-inference

 â”ƒ â”£ ğŸ“œinference.py

 â”ƒ â”£ ğŸ“œmodel_inference.dockerfile

 â”ƒ â”— ğŸ“œrequirements.txt

 â”£ ğŸ“‚Model-Training

 â”ƒ â”£ ğŸ“‚redundant

 â”ƒ â”£ ğŸ“œmodel_training.dockerfile

 â”ƒ â”£ ğŸ“œrequirements.txt

 â”ƒ â”— ğŸ“œtrain_model.py

 â”£ ğŸ“‚raw_data

 â”£ ğŸ“‚user-interface

 â”ƒ â”£ ğŸ“‚assets

 â”ƒ â”ƒ â”£ ğŸ“‚css

 â”ƒ â”ƒ â”— ğŸ“‚js

 â”ƒ â”£ ğŸ“‚static

 â”ƒ â”ƒ â”£ ğŸ“‚css

 â”ƒ â”ƒ â”ƒ â”— ğŸ“œstyle.css

 â”ƒ â”ƒ â”— ğŸ“‚js

 â”ƒ â”ƒ â”ƒ â”— ğŸ“œscript.js

 â”ƒ â”£ ğŸ“‚templates

 â”ƒ â”ƒ â”£ ğŸ“œindex.html

 â”ƒ â”ƒ â”£ ğŸ“œmodel_pred_csv.html

 â”ƒ â”ƒ â”— ğŸ“œmodel_pred_manual.html

 â”ƒ â”£ ğŸ“œrequirements.txt

 â”ƒ â”£ ğŸ“œweb_application.dockerfile

 â”ƒ â”— ğŸ“œwinequality_app.py

 â”£ ğŸ“‚volumes

 â”ƒ â”£ ğŸ“‚data

 â”ƒ â”ƒ â”£ ğŸ“œ.DS_Store

 â”ƒ â”ƒ â”£ ğŸ“œcleaned_wine_quality.csv

 â”ƒ â”ƒ â”— ğŸ“œwine_quality.json

 â”ƒ â”£ ğŸ“‚models

 â”ƒ â”ƒ â”— ğŸ“œsaved_model.pkl

 â”ƒ â”£ ğŸ“‚user

 â”ƒ â”ƒ â”£ ğŸ“œcleaned_input.csv

 â”ƒ â”ƒ â”£ ğŸ“œinput.csv

 â”ƒ â”ƒ â”— ğŸ“œpredictions.json

 â”ƒ â”£ ğŸ“‚userinput

 â”ƒ â”— ğŸ“œ.DS_Store

 â”£ ğŸ“œ.DS_Store

 â”£ ğŸ“œREAME.md

 â”— ğŸ“œrun.sh
 

## Data Preprocessing Container (data-preprocessing)
### Overview

The Data Preprocessing COntainer is designed to clean the raw CSV file from the training data and user input data (uploading a CSV or manual input through the UI)

Steps:
- Drop Unnecessary Columns
- Drop NaN values
- Drop Duplicates
- Format Numeric columns
- Encode categorical features
- Map target labels to a specific scale
- Prepare cleaned dataset for other tasks in the pipeline

This container is important in ensuring quality and consistent data in this pipeline.

### File Structure
â”£ ğŸ“‚data-preprocessing

â”ƒ â”£ ğŸ“‚data

â”ƒ â”£ ğŸ“‚raw_data

â”ƒ â”ƒ â”— ğŸ“œwine_quality_assignment.csv

â”ƒ â”£ ğŸ“‚__pycache__

â”ƒ â”£ ğŸ“œdata_preprocessing.dockerfile

â”ƒ â”£ ğŸ“œpreprocess.py

â”ƒ â”— ğŸ“œrequirements.txt

### Project Architecture
This section is deployed in a Kubernetes environment with the following configuration
- Deployment Configuration (defined in data-preprocessing.yaml)
    - /app/volumes/data: store cleaned dataset
    - /app/volumes/user: holds user related data

- Service Configuration (defined in data-preprocessing-service.yaml)
    - exposes the Data Preprocessing service at http://data-preprocessing-service:5004, which allows other containers to access it

- Volume Mounts
    - /app/volumes/data pushed to data-volume-pvc to store cleaned dataset
    - /app/volumes/user pushed to user-volume-pvc to store user uploaded data

### Data Flow Diagram
![alt text](image-1.png)
![alt text](image-2.png)
![alt text](image-3.png)
![alt text](image.png)

### Features & Functionalities
**Main Preprocessing Steps**
- Training data "wine_quality_assignment.csv" was retrieved from the "raw_data" folder
- Dropped "Sample" column
- Dropped NaN values, duplicates, outliers
- Format numeric columns to ensure correct data types
- Encode categorical features (White - 0, Red - 1)
- Maps "quality" from 1 to 5

**User Input Methods**
- CSV input: user can upload a CSV file through the UI, which is sent fromt he <code>/upload_csv</code> route
- Manual input: user can manually enter the wine features through the UI

**Output from Data Preprocessing**

Cleaned datasets saved in /app/volumes/data or /app/volumes/user as:
- cleaned_wine_quality.csv
- cleaned_input.csv

### preprocess.py
This script handles data preprocessing using Flask API
- /get-data: preprocess the training dataset and saves the cleaned version
- /process-user-input: preprocess the data uploaded by the user and save it as cleaned_input.csv

**convert_csv_to_json()**: convert raw CSV to JSON

**clean_column(column)**: define cleaning numeric columns by removing non-numeric characters

**preprocess_data_logic(df)**: main preprocessing function

### data_preprocessing.dockerfile
- Base Image: <code>python:3.9-slim</code>
- Steps:
    - install dependencies from <code>requirements.txt</code>
    - set up necessary directories for volume mount
    - expose port 5004 for API
    - start Flask application using "python preprocess.py" command

